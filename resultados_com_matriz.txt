KNN
              precision    recall  f1-score   support

           0     0.3521    0.4000    0.3745       125
           1     0.3958    0.3585    0.3762       106
           2     0.3022    0.3500    0.3243       120
           3     0.3364    0.2880    0.3103       125
           4     0.3254    0.3280    0.3267       125
           5     0.4322    0.4679    0.4493       109
           6     0.3800    0.3486    0.3636       109
           7     0.6638    0.6160    0.6390       125
           8     0.3830    0.4320    0.4060       125
           9     0.2453    0.2131    0.2281       122

    accuracy                         0.3804      1191
   macro avg     0.3816    0.3802    0.3798      1191
weighted avg     0.3814    0.3804    0.3798      1191

Confusion Matrix:
[[50 18  7  9 10  1 10  1 10  9]
 [25 38  8  7  3  2  6  2  7  8]
 [ 8  3 42  7  9 13  8  7 11 12]
 [12  5 11 36 19  5  6  4 13 14]
 [11  7  8 19 41  5  5  5 10 14]
 [ 4  2 24  5  5 51  1  8  4  5]
 [ 6  8 14  5  7 12 38  6  9  4]
 [ 2  6  6  2 10  8  3 77  9  2]
 [10  5  6  8 10  3 12  5 54 12]
 [14  4 13  9 12 18 11  1 14 26]]

 ----------------------------------------------------------------------------

Fitting 5 folds for each of 90 candidates, totalling 450 fits
SVM
              precision    recall  f1-score   support

           0     0.4453    0.4560    0.4506       125
           1     0.5152    0.4811    0.4976       106
           2     0.4395    0.5750    0.4982       120
           3     0.4942    0.6800    0.5724       125
           4     0.4508    0.4400    0.4453       125
           5     0.6262    0.6147    0.6204       109
           6     0.4679    0.4679    0.4679       109
           7     0.8556    0.6160    0.7163       125
           8     0.7041    0.5520    0.6188       125
           9     0.4679    0.4180    0.4416       122

    accuracy                         0.5306      1191
   macro avg     0.5467    0.5301    0.5329      1191
weighted avg     0.5478    0.5306    0.5335      1191

Confusion Matrix:
[[57 21  2  8 11  3  8  0  3 12]
 [23 51  5  5  9  3  3  0  3  4]
 [ 9  1 69  9  6  8  9  4  2  3]
 [ 3  1 11 85  9  1  2  0  2 11]
 [15  4  5 27 55  0  8  3  3  5]
 [ 3  1 21  7  5 67  2  1  0  2]
 [ 3  6 14  3  8  8 51  0  7  9]
 [ 2  4  8  8  9  8  7 77  1  1]
 [ 3  7  3  9  7  1 10  5 69 11]
 [10  3 19 11  3  8  9  0  8 51]]
 
 ----------------------------------------------------------------------------
 
 MLP, lbfgs
              precision    recall  f1-score   support

           0     0.4393    0.3760    0.4052       125
           1     0.3804    0.3302    0.3535       106
           2     0.4487    0.5833    0.5072       120
           3     0.4315    0.6800    0.5280       125
           4     0.5052    0.3920    0.4414       125
           5     0.5508    0.5963    0.5727       109
           6     0.3592    0.3394    0.3491       109
           7     0.8370    0.6160    0.7097       125
           8     0.5041    0.4960    0.5000       125
           9     0.3774    0.3279    0.3509       122

    accuracy                         0.4761      1191
   macro avg     0.4833    0.4737    0.4718      1191
weighted avg     0.4862    0.4761    0.4741      1191

Confusion Matrix:
[[32 28  0 47 14  1  0  0  2  1]
 [28 22  0 39 12  3  0  0  2  0]
 [ 1 14  2 52 12  9 24  5  0  1]
 [ 2  5  0 96 19  3  0  0  0  0]
 [ 2  7  0 64 47  2  2  1  0  0]
 [ 0  5  1 45 12 44  1  1  0  0]
 [ 2 19  0 44 16  8 14  5  0  1]
 [ 1  8  0 20 12 38  2 43  1  0]
 [ 4 15  0 53 35  0  7  1  9  1]
 [ 3 20  0 69 15  3  3  0  3  6]]
 
 ----------------------------------------------------------------------------
 
MLP, sgd
              precision    recall  f1-score   support

           0     0.4773    0.5040    0.4903       125
           1     0.4946    0.4340    0.4623       106
           2     0.4962    0.5500    0.5217       120
           3     0.5600    0.5600    0.5600       125
           4     0.4453    0.4880    0.4656       125
           5     0.6610    0.7156    0.6872       109
           6     0.4286    0.4404    0.4344       109
           7     0.7589    0.6800    0.7173       125
           8     0.6333    0.6080    0.6204       125
           9     0.4495    0.4016    0.4242       122

    accuracy                         0.5390      1191
   macro avg     0.5405    0.5382    0.5384      1191
weighted avg     0.5415    0.5390    0.5393      1191

Confusion Matrix:
[[63 21  4  4 10  0 11  1  3  8]
 [29 46  3  2  9  3  6  0  4  4]
 [ 5  1 66  8  6  9 11  7  3  4]
 [ 5  2  6 70 15  1  3  1  5 17]
 [ 9  4  6 15 61  6 10  3  5  6]
 [ 0  2  9  2  7 78  4  5  0  2]
 [ 4  7 15  5  9  4 48  5  4  8]
 [ 3  3  6  5  6  8  8 85  1  0]
 [ 7  2  4  5  8  2  6  4 76 11]
 [ 7  5 14  9  6  7  5  1 19 49]]
 
 ----------------------------------------------------------------------------
 
MLP, adam
              precision    recall  f1-score   support

           0     0.5222    0.3760    0.4372       125
           1     0.4587    0.4717    0.4651       106
           2     0.3702    0.5583    0.4452       120
           3     0.5390    0.6080    0.5714       125
           4     0.5701    0.4880    0.5259       125
           5     0.6941    0.5413    0.6082       109
           6     0.4198    0.5046    0.4583       109
           7     0.6855    0.6800    0.6827       125
           8     0.6195    0.5600    0.5882       125
           9     0.4545    0.4098    0.4310       122

    accuracy                         0.5206      1191
   macro avg     0.5334    0.5198    0.5213      1191
weighted avg     0.5348    0.5206    0.5225      1191

Confusion Matrix:
[[47 29 11  7  7  3 11  1  2  7]
 [20 50  6  6  4  3  5  1  5  6]
 [ 2  0 67 10  2  4 17 10  4  4]
 [ 2  3 10 76  8  2  4  2  5 13]
 [ 8  6 10 13 61  2  7  6  7  5]
 [ 0  1 17  4  2 59 11  7  1  7]
 [ 0  4 15  5  7  2 55  7  9  5]
 [ 1  4 10  5  4  7  7 85  1  1]
 [ 2  6  9  7  6  0  9  4 70 12]
 [ 8  6 26  8  6  3  5  1  9 50]]
 
 ----------------------------------------------------------------------------
 
Random Forest
              precision    recall  f1-score   support

           0     0.4586    0.4880    0.4729       125
           1     0.5897    0.4340    0.5000       106
           2     0.4931    0.5917    0.5379       120
           3     0.4884    0.5040    0.4961       125
           4     0.6800    0.2720    0.3886       125
           5     0.7895    0.5505    0.6486       109
           6     0.3380    0.4404    0.3825       109
           7     0.8100    0.6480    0.7200       125
           8     0.6018    0.5440    0.5714       125
           9     0.3053    0.5656    0.3966       122

    accuracy                         0.5046      1191
   macro avg     0.5554    0.5038    0.5114      1191
weighted avg     0.5556    0.5046    0.5117      1191

Confusion Matrix:
[[61 15  2  8  4  0 11  1  3 20]
 [26 46  2  3  1  1  5  2  6 14]
 [ 4  0 71  5  1  2 13  4  2 18]
 [ 3  2  4 63  4  0  7  0  3 39]
 [13  4  4 23 34  2 13  3 11 18]
 [ 0  1 19  1  0 60 13  2  2 11]
 [ 9  2 15  9  1  1 48  4  5 15]
 [ 1  3 10  4  2  9  5 81  5  5]
 [ 6  2  3  8  2  1 15  3 68 17]
 [10  3 14  5  1  0 12  0  8 69]]
 
 ----------------------------------------------------------------------------
 
Decision Tree
              precision    recall  f1-score   support

           0     0.2301    0.2080    0.2185       125
           1     0.3146    0.2642    0.2872       106
           2     0.3134    0.3500    0.3307       120
           3     0.2889    0.3120    0.3000       125
           4     0.1867    0.1120    0.1400       125
           5     0.5942    0.3761    0.4607       109
           6     0.1705    0.2018    0.1849       109
           7     0.5932    0.5600    0.5761       125
           8     0.3410    0.4720    0.3960       125
           9     0.2564    0.3279    0.2878       122

    accuracy                         0.3199      1191
   macro avg     0.3289    0.3184    0.3182      1191
weighted avg     0.3279    0.3199    0.3186      1191

Confusion Matrix:
[[26 14  8  7  7  3 14  8 19 19]
 [14 28  7  9 16  0  7  6 12  7]
 [ 9  2 42 14  5  7 17  4  5 15]
 [14 10  4 39  9  0  4  4 15 26]
 [12 10  9 19 14  2 13  9 25 12]
 [ 8  3  7 10  3 41 17  9  6  5]
 [14  6 15 12  5  3 22  4 14 14]
 [ 4  0  8  7  2 10  8 70  6 10]
 [ 6  8  5 11  9  2 14  3 59  8]
 [ 6  8 29  7  5  1 13  1 12 40]]
 
 ----------------------------------------------------------------------------
 
 Combined Results
              precision    recall  f1-score   support

           0     0.4487    0.5600    0.4982       125
           1     0.5165    0.4434    0.4772       106
           2     0.4491    0.6250    0.5226       120
           3     0.5724    0.6640    0.6148       125
           4     0.5688    0.4960    0.5299       125
           5     0.7273    0.6606    0.6923       109
           6     0.4530    0.4862    0.4690       109
           7     0.8454    0.6560    0.7387       125
           8     0.7228    0.5840    0.6460       125
           9     0.4679    0.4180    0.4416       122

    accuracy                         0.5609      1191
   macro avg     0.5772    0.5593    0.5630      1191
weighted avg     0.5786    0.5609    0.5644      1191

Confusion Matrix:
[[70 21  3  6  7  0  8  1  1  8]
 [31 47  6  4  3  2  5  0  3  5]
 [ 5  0 75  8  4  4 13  4  3  4]
 [ 4  4  7 83  8  0  1  0  2 16]
 [13  4  9 18 62  2  6  2  5  4]
 [ 2  0 18  2  3 72  6  2  1  3]
 [ 8  3 17  3  5  5 53  3  5  7]
 [ 3  5 11  7  5  7  3 82  0  2]
 [ 7  2  4  7  6  1 13  3 73  9]
 [13  5 17  7  6  6  9  0  8 51]]